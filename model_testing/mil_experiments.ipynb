{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "B6XEPRGmEP_9"
      },
      "id": "B6XEPRGmEP_9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4c7a83b",
      "metadata": {
        "id": "e4c7a83b"
      },
      "outputs": [],
      "source": [
        "!pip install grad-cam torchcam numpy==1.26.4 pandas==2.2.2 seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c1341a",
      "metadata": {
        "id": "21c1341a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "import torchvision.models as models\n",
        "from torchvision.models import (\n",
        "    resnet18, resnet50, resnet152, ResNet18_Weights,\n",
        "    efficientnet_b0, EfficientNet_B0_Weights,\n",
        "    vgg16, VGG16_Weights,\n",
        "    inception_v3, Inception_V3_Weights\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from pytorch_grad_cam import GradCAM, GradCAMPlusPlus\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "b2GZGOIHT9S2"
      },
      "id": "b2GZGOIHT9S2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "p2asusfrE1Ve"
      },
      "id": "p2asusfrE1Ve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SbrW6ngtEyuJ"
      },
      "id": "SbrW6ngtEyuJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "On7uh6fLt-Zz"
      },
      "id": "On7uh6fLt-Zz"
    },
    {
      "cell_type": "code",
      "source": [
        "class MILImageFolder(Dataset):\n",
        "  def __init__(self, root, transform, bag_size=10):\n",
        "    self.dataset = datasets.ImageFolder(root=root, transform=transform)\n",
        "    self.bag_size = bag_size\n",
        "\n",
        "    self.label_to_indices = {}\n",
        "    for idx, (_, label) in enumerate(self.dataset.samples):\n",
        "        self.label_to_indices.setdefault(label, []).append(idx)\n",
        "\n",
        "    self.bags = []\n",
        "    for label, indices in self.label_to_indices.items():\n",
        "        np.random.shuffle(indices)\n",
        "        for i in range(0, len(indices) - bag_size + 1, bag_size):\n",
        "            bag_indices = indices[i:i + bag_size]\n",
        "            self.bags.append((bag_indices, label))\n",
        "    np.random.shuffle(self.bags)\n",
        "\n",
        "    # Save bag labels for stratified splits\n",
        "    self.targets = np.array([label for (_, label) in self.bags])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.bags)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    bag_indices, bag_label = self.bags[index]\n",
        "    bag_images = [self.dataset[i][0] for i in bag_indices]\n",
        "    bag_tensor = torch.stack(bag_images)\n",
        "    return bag_tensor, bag_label"
      ],
      "metadata": {
        "id": "gzQ1_ccit9-3"
      },
      "id": "gzQ1_ccit9-3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Dataset directories\n",
        "train_augmented_dir = '/content/drive/MyDrive/GBCUD/dataset/train'\n",
        "output_test_folder = '/content/drive/MyDrive/GBCUD/dataset/test'\n",
        "\n",
        "#  MIL datasets.\n",
        "# bag will contain 10 images from the same class\n",
        "train_dataset = MILImageFolder(root=train_augmented_dir, transform=train_transforms, bag_size=10)\n",
        "test_dataset = MILImageFolder(root=output_test_folder, transform=test_transforms, bag_size=10)\n",
        "\n",
        "# Create stratified train/validation split on bag labels.\n",
        "targets = train_dataset.targets\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(targets)),\n",
        "    test_size=0.2,\n",
        "    stratify=targets,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_subset = Subset(train_dataset, train_idx)\n",
        "val_subset = Subset(train_dataset, val_idx)\n",
        "\n",
        "# Create a weighted sampler for the training subset.\n",
        "train_targets = targets[train_idx]\n",
        "class_counts = np.bincount(train_targets)\n",
        "sample_weights = np.array([1.0 / class_counts[label] for label in train_targets])\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)"
      ],
      "metadata": {
        "id": "fFWv96UBubhw"
      },
      "id": "fFWv96UBubhw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "HFILAcwLEXXz"
      },
      "id": "HFILAcwLEXXz"
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionMIL(nn.Module):\n",
        "  def __init__(self, backbone_name=\"resnet18\", num_classes=3, pretrained=True):\n",
        "    super(AttentionMIL, self).__init__()\n",
        "\n",
        "    self.L = 512\n",
        "    self.D = 256\n",
        "    self.K = 1\n",
        "\n",
        "    #  load pretrained backbone\n",
        "    self.feature_extractor, backbone_output_dim = self.get_backbone(backbone_name, pretrained)\n",
        "\n",
        "    self.pool = nn.AdaptiveAvgPool2d((30, 30))\n",
        "\n",
        "    self.extra_conv_layers = nn.Sequential(\n",
        "        nn.Conv2d(backbone_output_dim, 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.feature_extractor_part2 = nn.Sequential(\n",
        "        nn.Linear(64 * 30 * 30, self.L),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(self.L, self.L),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "    )\n",
        "\n",
        "    self.attention = nn.Sequential(\n",
        "        nn.Linear(self.L, self.D),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(self.D, self.K)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Linear(self.L * self.K, num_classes)\n",
        "\n",
        "  def get_backbone(self, name, pretrained):\n",
        "    if name == \"resnet18\":\n",
        "      model = resnet18(weights=ResNet18_Weights.DEFAULT if pretrained else None)\n",
        "      return nn.Sequential(*list(model.children())[:-2]), 512\n",
        "    elif name == \"resnet50\":\n",
        "      model = resnet50(pretrained=pretrained)\n",
        "      return nn.Sequential(*list(model.children())[:-2]), 2048\n",
        "    elif name == \"resnet152\":\n",
        "      model = resnet152(pretrained=pretrained)\n",
        "      return nn.Sequential(*list(model.children())[:-2]), 2048\n",
        "    elif name == \"efficientnet_b0\":\n",
        "      model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT if pretrained else None)\n",
        "      return model.features, 1280\n",
        "    elif name == \"vgg16\":\n",
        "      model = vgg16(weights=VGG16_Weights.DEFAULT if pretrained else None)\n",
        "      return nn.Sequential(*list(model.features.children())[:-1]), 512\n",
        "    elif name == \"inception_v3\":\n",
        "      model = inception_v3(weights=Inception_V3_Weights.DEFAULT if pretrained else None, aux_logits=False)\n",
        "      return nn.Sequential(*list(model.children())[:-2]), 2048\n",
        "    else:\n",
        "      raise ValueError(f\"Unsupported backbone: {name}\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, bag_size, C, H, W = x.shape\n",
        "    x = x.view(B * bag_size, C, H, W)\n",
        "    features = self.feature_extractor(x)\n",
        "    features = self.pool(features)\n",
        "    features = self.extra_conv_layers(features)\n",
        "    features = features.view(B * bag_size, -1)\n",
        "    H_features = self.feature_extractor_part2(features)\n",
        "    H_features = H_features.view(B, bag_size, -1)\n",
        "\n",
        "    A = self.attention(H_features.view(B * bag_size, -1))\n",
        "    A = A.view(B, bag_size, self.K).transpose(1, 2)\n",
        "\n",
        "    temperature = 0.5\n",
        "    A = F.softmax(A / temperature, dim=2)\n",
        "\n",
        "    M = torch.bmm(A, H_features)\n",
        "    M = M.view(B, -1)\n",
        "    logits = self.classifier(M)\n",
        "    probs = F.log_softmax(logits, dim=1).exp()\n",
        "    return logits, probs, A\n",
        "\n",
        "    def calculate_classification_error(self, X, Y):\n",
        "      logits, _, _ = self.forward(X)\n",
        "      preds = torch.argmax(logits, dim=1)\n",
        "      error = 1.0 - preds.eq(Y).cpu().float().mean().item()\n",
        "      return error, preds\n",
        "\n",
        "  def calculate_objective(self, X, Y):\n",
        "    logits, _, A = self.forward(X)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss = criterion(logits, Y)\n",
        "    return loss, A\n",
        "\n",
        "  def get_attention_map(self, x):\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      if x.ndimension() == 5:\n",
        "        x = x.squeeze(0)\n",
        "      elif x.ndimension() == 4:\n",
        "        pass\n",
        "      else:\n",
        "        raise ValueError(f\"wrong input shape in get_attention_map: {x.shape}\")\n",
        "\n",
        "      bag_size, C, H, W = x.shape\n",
        "\n",
        "      # Extract features\n",
        "      features = self.feature_extractor(x)\n",
        "      features = self.pool(features)\n",
        "      features = self.extra_conv_layers(features)\n",
        "\n",
        "      features = features.view(bag_size, -1)\n",
        "      H_features = self.feature_extractor_part2(features)\n",
        "\n",
        "      A = self.attention(H_features)\n",
        "      A = F.softmax(A, dim=0)\n",
        "\n",
        "      att_map = A[:, 0].cpu().numpy()\n",
        "\n",
        "      return att_map"
      ],
      "metadata": {
        "id": "mAgeGLQSJdRX"
      },
      "id": "mAgeGLQSJdRX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Evaluate Model"
      ],
      "metadata": {
        "id": "Ndo_WKeZEhay"
      },
      "id": "Ndo_WKeZEhay"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f220e83",
      "metadata": {
        "id": "2f220e83"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    return total_loss / len(dataloader), acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028cdc03",
      "metadata": {
        "id": "028cdc03"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    return total_loss / len(dataloader), acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230d362d",
      "metadata": {
        "id": "230d362d"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model_name, train_loader, val_loader, lr=1e-4, epochs=5):\n",
        "    model = build_model(model_name)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    print(f\"Training {model_name} for {epochs} epochs...\")\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "        val_loss, val_acc, val_f1 = evaluate(model, val_loader, criterion)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} | Val F1: {val_f1:.3f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment"
      ],
      "metadata": {
        "id": "GE78rKhoElBn"
      },
      "id": "GE78rKhoElBn"
    },
    {
      "cell_type": "code",
      "source": [
        "model = run_experiment(\"resnet50\", train_loader, val_loader, lr=1e-4, epochs=10)"
      ],
      "metadata": {
        "id": "1tupZ6KRAfDf"
      },
      "id": "1tupZ6KRAfDf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}